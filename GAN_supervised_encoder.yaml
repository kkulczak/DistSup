Datasets:
  train:
    class_name: distsup.data.FixedDatasetLoader
    batch_size: 32
    dataset:
      class_name: egs.scribblelens.simple_dataset.TextScribbleLensDataset
      shape_as_image: true
      max_lenght: 75
      tokens_protos:
        class_name: distsup.modules.gan.utils.EncoderTokensProtos
        path: "data/55_acc_letters_protoypes.npz"
        protos_per_token: 1
    shuffle: true
    num_workers: 0
    drop_last: true
  dev:
    class_name: distsup.data.FixedDatasetLoader
    batch_size: 32
    dataset:
      class_name: egs.scribblelens.simple_dataset.TextScribbleLensDataset
      shape_as_image: true
      eval_size_only: true
      max_lenght: 75
      tokens_protos:
        class_name: distsup.modules.gan.utils.EncoderTokensProtos
        path: "data/55_acc_letters_protoypes.npz"
        protos_per_token: 1
    shuffle: false
    num_workers: 0
    drop_last: true

Model:
  class_name: distsup.models.GAN_representation_learners.GanRepresentationLearner
  image_height: 68
  encoder:
    class_name: distsup.modules.convolutional.ConvStack1D
    hid_channels: 68
    num_strided: 2
    num_dilated: 2
    num_postdil: 3
# Tą flagą zamieniam ConvStack1D w identyczność nie tracąc kompatybilności wstecznej
    identity: True
  reconstructor:
    class_name: distsup.modules.reconstructors.NullReconstructor
#  aux_heads:
#    enc_sup:
#      layer: encoder
#      target: alignment
#      predictor:
#        class_name: distsup.modules.predictors.FramewisePredictor
#        aggreg: 1
#        use_two_layer_predictor: False
#      bp_to_main: True
  gan_generator:
    class_name: distsup.modules.gan.generator_net.LinearGeneratorNet
    inject_gan_config: True
  gan_discriminator:
    class_name: distsup.modules.gan.discriminator_net.DiscriminatorNet
    inject_gan_config: True
#  letters_protos:
#    class_name: distsup.modules.gan.utils.EncoderTokensProtos
#    path: "data/encoder_letter_prototypes.npz"
#    protos_per_token: 1
#    deterministic: True
#    preproc_softmax: True
#    use_only_recognized: True
#    use_one_hot: False
#  alignment_shuffler:
#    class_name: distsup.modules.gan.alignment_shuffler.AlignmentShuffler
#    mode: id #One From (id, constant, protos)
#    path: "data/encoder_letter_prototypes.npz"
#    constant_noise: 0.1


Trainer:
  class_name: distsup.gan_trainer.TrainerForGan
  real_samples_dataloader:
    class_name: distsup.data.FixedDatasetLoader
    batch_size: 32
    dataset:
      class_name: egs.scribblelens.simple_dataset.TextScribbleLensDataset
      shape_as_image: false
      max_lenght: 75
    shuffle: true
    num_workers: 0
    drop_last: true
  checkpointer:
    every_n_hours: 4
  learning_rate: 0.001
  learning_rate_scheduler:
    class_name: torch.optim.lr_scheduler.ReduceLROnPlateau
    factor: 0.5
    patience: 2
  output_frequency: 20
  num_epochs: 100
  optimizer_name: Adam
  inject_gan_config: True
  distsup_training: False

#to będzie wstrzyknięte do generatora, dyscriminatora oraz Trenera jako Klasa GanConfig
# distsup.modules.gan.data_types.GanConfig
# W ten sposób mogę współdzielić ustawienia między klasami.
# Jest to brzydki hack :(
gan_config:
# Ustawienie na 1 wyłącza funkcjonalnosć. Wzięte od Chińczyków
  concat_window: 1
  repeat: 1
# Uproszczenie zadania
# Zmniejszyłem do 7 dostępne literki
# W ScribleLensdataset biorę alignment mod 7 [egs/scribblelens/data.py:733]
# Trzeba zmienić
  dictionary_size: 68
# Tutaj definiujemy długość wyjścia z encodera
# Jeżeli alignment zawiera więcej literek, to po prostu przycinam tą ilość
  max_sentence_length: 75
# waga dla gp_penalty Chińskiego GANa
  gradient_penalty_ratio: 10.0
  use_all_letters: False
  supervised: False
  batch_inject_noise: 0.0
  sample_from_middle_of_frame: False
  filter_blanks: False
  # Discriminator part
  dis_steps: 3
  dis_emb_size: 256
  dis_hidden_1_size: 1024
  dis_hidden_2_size: 1024
  dis_maxpool_reduction: 8
  dis_learning_rate: 0.002
  # Generator part
  gen_steps: 1
  gen_hidden_size: 512
  gen_learning_rate: 0.001
  