Datasets:
  train:
    class_name: FixedDatasetLoader
    batch_size: 32
    dataset:
      class_name: distsup.data.ChunkedDataset
      dataset:
        class_name: egs.scribblelens.data.ScribbleLensDataset
        split: train
        alignment_root: "data/scribblelens.paths.1.4b.zip"
        vocabulary: egs/scribblelens/tasman.alphabet.plus.space.mode5.json
#        alignment_mod: 7
      chunk_len: 360
      pad_with_zeros_if_short: true
      training: true
      varlen_fields: [image, alignment]
      drop_fields: [
        text,
        alignment_rle,
        page_side,
        page
      ]
    rename_dict:
        image: features
    shuffle: true
    num_workers: 4
    drop_last: True
  dev:
    class_name: PaddedDatasetLoader
    batch_size: 32
    dataset:
      class_name: egs.scribblelens.data.ScribbleLensDataset
      split: test
      alignment_root: "data/scribblelens.paths.1.4b.zip"
      vocabulary: egs/scribblelens/tasman.alphabet.plus.space.mode5.json
#      alignment_mod: 7
    rename_dict:
        image: features
    shuffle: false
    num_workers: 4
    drop_last: True

Model:
  class_name: distsup.models.GAN_representation_learners.GanRepresentationLearner
  image_height: 32
  encoder:
    class_name: distsup.modules.convolutional.ConvStack1D
    hid_channels: 68
    num_strided: 2
    num_dilated: 2
    num_postdil: 3
# Tą flagą zamieniam ConvStack1D w identyczność nie tracąc kompatybilności wstecznej
    identity: True
  reconstructor:
    class_name: distsup.modules.reconstructors.NullReconstructor
#  aux_heads:
#    enc_sup:
#      layer: encoder
#      target: alignment
#      predictor:
#        class_name: distsup.modules.predictors.FramewisePredictor
#        aggreg: 1
#        use_two_layer_predictor: False
#      bp_to_main: True
  gan_generator:
    class_name: distsup.modules.gan.generator_net.LinearGeneratorNet
    inject_gan_config: True
  gan_discriminator:
    class_name: distsup.modules.gan.discriminator_maxpool.MaxPoolDiscriminator
    inject_gan_config: True


Trainer:
  class_name: distsup.gan_trainer.TrainerForGan
  checkpointer:
    every_n_hours: 4
  learning_rate: 0.001
  learning_rate_scheduler:
    class_name: torch.optim.lr_scheduler.ReduceLROnPlateau
    factor: 0.5
    patience: 2
  output_frequency: 20
  num_epochs: 10
  optimizer_name: Adam
  inject_gan_config: True
  distsup_training: False

#to będzie wstrzyknięte do generatora, dyscriminatora oraz Trenera jako Klasa GanConfig
# distsup.modules.gan.data_types.GanConfig
# W ten sposób mogę współdzielić ustawienia między klasami.
# Jest to brzydki hack :(
gan_config:
# Ustawienie na 1 wyłącza funkcjonalnosć. Wzięte od Chińczyków
  concat_window: 1
  repeat: 1
# Uproszczenie zadania
# Zmniejszyłem do 7 dostępne literki
# W ScribleLensdataset biorę alignment mod 7 [egs/scribblelens/data.py:733]
# Trzeba zmienić
  dictionary_size: 68
# Tutaj definiujemy długość wyjścia z encodera
# Jeżeli alignment zawiera więcej literek, to po prostu przycinam tą ilość
  max_sentence_length: 64
# waga dla gp_penalty Chińskiego GANa
  gradient_penalty_ratio: 10.0
  use_all_letters: False
  supervised: False
  batch_inject_noise: 0.0
  # Discriminator part
  dis_steps: 3
  dis_emb_size: 256
  dis_hidden_1_size: 1024
  dis_hidden_2_size: 1024
  dis_maxpool_reduction: 8
  dis_learning_rate: 0.002
  # Generator part
  gen_steps: 1
  gen_hidden_size: 64
  gen_learning_rate: 0.001
  